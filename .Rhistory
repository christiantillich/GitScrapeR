model_decline_score = min(model_decline_score)
,p = min(1-model_decline_score)
) %>%
qplot(
model_decline_score
,data=.
,color = past_flg
,fill = past_flg
,geom = "density"
,alpha = 0.10
) + theme_BA +
ggtitle("Score Distribution")
#Define the p ~ explan function.
param <- function(explans, coef){
#explans <- flg.create(explans, 'term')
explans <- as.matrix(explans)
as.numeric(explans %*% coef)
}
#Objective function.
obj <- function(
coef
,p.fun= function(x) param(x,coef)
,explans = c('term','score_group')
,y = "returns"
,x = 'complete_pct'
,n = 100
,data = df.recent # %>% filter(term %in% c(12,24,36,48,60))
){
y <- as.symbol(y)
x <- as.symbol(x)
#Aggregate the data set by model score groupings.
data <- data %>%
mutate(score_group = 1-round(model_decline_score/5,2)*5) %>%
data.agg(grp=c(explans,'month','installment_number')) %>%
filter(installment_number <= n, remaining > 30) %>%
mutate_(.dots = x, x=x) %>% mutate_(.dots=y, y=y)
data$p <- p.fun(data[,explans])
#Calculate the error from the curve defined by p.
data <- data %>%
mutate(y.hat = log(p*x + 0.0266*apr_percentage + exp(-1))) %>%
mutate(err = remaining*(y.hat - y)^2)
#Return the data set (with the y.hat and error term).
return(data)
}
#Quick distribution of the model score.
rbind(df, df.recent) %>%
mutate(past_flg = funding_date <= as.Date('2014-06-01')) %>%
group_by(id, past_flg) %>%
summarize(
model_decline_score = min(model_decline_score)
,p = min(1-model_decline_score)
) %>%
qplot(
model_decline_score
,data=.
,color = past_flg
,fill = past_flg
,geom = "density"
,alpha = 0.10
) + theme_BA +
ggtitle("Score Distribution")
#Define the p ~ explan function.
param <- function(explans, coef){
#explans <- flg.create(explans, 'term')
explans <- as.matrix(explans)
as.numeric(explans %*% coef)
}
#Objective function.
obj <- function(
coef
,p.fun= function(x) param(x,coef)
,explans = c('term','score_group')
,y = "returns"
,x = 'complete_pct'
,n = 100
,data = df.recent # %>% filter(term %in% c(12,24,36,48,60))
){
y <- as.symbol(y)
x <- as.symbol(x)
#Aggregate the data set by model score groupings.
data <- data %>%
mutate(score_group = 1-round(model_decline_score/5,2)*5) %>%
data.agg(grp=c(explans,'month','installment_number')) %>%
filter(installment_number <= n, remaining > 30) %>%
mutate_(.dots = x, x=x) %>% mutate_(.dots=y, y=y)
data$p <- p.fun(data[,explans])
#Calculate the error from the curve defined by p.
data <- data %>%
mutate(y.hat = log(p*x + 0.0266*apr_percentage + exp(-1))) %>%
mutate(err = remaining*(y.hat - y)^2)
#Return the data set (with the y.hat and error term).
return(data)
}
#Choose explan params to minimize squared error.
helper <- function(x) sum(obj(coef=x, n=4)$err)
obj.min <- optim(c(0,0), helper)
head(df)
#Source the Core Function/Data script.
lib <- "C:/Users/ctilli82/Desktop/LTV_Projections/R"
paste(lib,"0_Core_Functions_and_Data.R",sep="/") %>% source
print(getSrcFilename(function(x) {x}))
#If you need to rerun...
print(lib) #This should move up to the top directory, LTV_Projections.
#paste(lib,"Data_Grabber","data_grabber.R",sep="/") %>% source
#Build a function to act as the model.
mdl <- function(t, prof, term, apr){
p = 0.6700*prof + 0.0127*term
return(log(p*t + exp(-1)))
}
#Create a funded-on-week variable.
fow <- function(x) x - wday(x) + 1
DF$week <- DF$funding_date %>% as.Date %>% fow
#For every loan, take the most recent installment.
monitor.sum <- DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number)) %>%
merge(DF) %>%
data.prep %>%
filter(!is.na(model_decline_score)) %>% #There's about 300.
mutate(
expected_return_pct =
mdl(installment_number/term, 1-model_decline_score, term)
,expected_returns = expected_return_pct * amount
,final_expected_return_pct = mdl(1, 1-model_decline_score, term)
) %>%
group_by(week) %>%
summarize(
actual_net_cash = sum(cumulative_net_cash)
,actual_return_rate = sum(cumulative_net_cash)/sum(amount)
,expected_net_cash = sum(expected_returns)
,expected_return_rate = mean(expected_return_pct)
,expected_final_return_rate = mean(final_expected_return_pct)
) %>% as.data.frame
####Present the data somehow.
#45* plot.
qplot(
expected_return_rate
,actual_return_rate
,data = monitor.sum
,main = "Expected vs. Actuals - Weekly"
) + theme_BA +
geom_line(aes(y=expected_return_rate)) #+
#expand_limits(x=c(-1,1), y=c(-1,1))
#Time series
qplot(
week
,actual_return_rate
,data = monitor.sum
,main = "Expected vs. Actuals - Weekly"
,color = I("darkolivegreen4")
) + theme_BA +
geom_point(aes(y=expected_return_rate), color="orange") +
geom_line(
aes(y = expected_final_return_rate)
,size=I(1.1)
,color="black"
)
DF %>%
group_by(id)
#Build a function to act as the model.
mdl <- function(t, prof, term){
p = 0.6700*prof + 0.0127*term
return(log(p*t + exp(-1)))
}
#Create a funded-on-week variable.
fow <- function(x) x - wday(x) + 1
DF$week <- DF$funding_date %>% as.Date %>% fow
#For every loan, take the most recent installment.
monitor.sum <- DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number)) %>%
merge(DF) %>%
data.prep %>%
filter(!is.na(model_decline_score)) %>% #There's about 300.
mutate(
expected_return_pct =
mdl(installment_number/term, 1-model_decline_score, term)
,expected_returns = expected_return_pct * amount
,final_expected_return_pct = mdl(1, 1-model_decline_score, term)
) %>%
group_by(week) %>%
summarize(
actual_net_cash = sum(cumulative_net_cash)
,actual_return_rate = sum(cumulative_net_cash)/sum(amount)
,expected_net_cash = sum(expected_returns)
,expected_return_rate = mean(expected_return_pct)
,expected_final_return_rate = mean(final_expected_return_pct)
) %>% as.data.frame
####Present the data somehow.
#45* plot.
qplot(
expected_return_rate
,actual_return_rate
,data = monitor.sum
,main = "Expected vs. Actuals - Weekly"
) + theme_BA +
geom_line(aes(y=expected_return_rate)) #+
#expand_limits(x=c(-1,1), y=c(-1,1))
#Time series
qplot(
week
,actual_return_rate
,data = monitor.sum
,main = "Expected vs. Actuals - Weekly"
,color = I("darkolivegreen4")
) + theme_BA +
geom_point(aes(y=expected_return_rate), color="orange") +
geom_line(
aes(y = expected_final_return_rate)
,size=I(1.1)
,color="black"
)
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number)) %>%
merge(DF) %>%
data.prep %>%
filter(!is.na(model_decline_score)) %>% #There's about 300.
mutate(
expected_return_pct =
mdl(installment_number/term, 1-model_decline_score, term)
,expected_returns = expected_return_pct * amount
,final_expected_return_pct = mdl(1, 1-model_decline_score, term)
)
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number)) %>%
merge(DF) %>%
data.prep %>%
filter(!is.na(model_decline_score))
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number)) %>%
merge(DF) %>%
data.prep
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number))
head(DF)
head(DF,100)
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number))
library(dplyr)
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number))
head(DF)
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number))
nrow(DF)
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number))
DF %>%
group_by(id) %>%
summarize(installment_number = max(installment_number)) %>%
merge(DF)
list.repos
# RProfile
# Packages that I want to always load.
library(devtools)
library(berdie)
library(magrittr)
library(stats)
library(plyr)
library(dplyr)
#Access Tokens
GITHUB_USER = 'christiantillich'
GITHUB_TOKEN = 'dfd1cd4b8afd6d3544b1250249162cdb70b6b9ab'
options(avant.api_v1_key = 'MTVhZDUxNTJkNzdkMzU5MGI')
options(avant.api_v1_url = 'analytics-adhoc-092915.herokuapp.com/api/modeling/v1')
options(avant.api_password = 'MTVhZDUxNTJkNzdkMzU5MGI')
options(avant.api_url = 'analytics-adhoc-092915.herokuapp.com/api/9b49bc90e9240eb7d0b70a9615ad5152d77d3590b66b8a5c5867e8c4c5fcb372/credit_model/')
#Some useful global paths
path.dropbox <- "C:/Users/ctilli82/Dropbox (AvantCredit.com)"
path.files <- paste0(path.dropbox,"/Christian Tillich")
path.projects <- paste0(path.files,"/Projects")
path.tech <- paste0(path.files,"/Tech")
path.git <- "C:/GitRepos"
#Setting Global options that berdie is going to pick up on.
options(avant.database.yml = '~/config/database.yml')
options(berdie.database.yml = '~/config/database.yml')
#Setting up the looker.yml file
options(syberia.root = 'C:/Users/ctilli82/Documents')
#Setting up s3 path
options(s3mpi.path = 'C:/Users/ctilli82/Documents/.s3cache/data')
#Source Everything in AnalyTools
source.all <- function(path){
path %>%
paste(., list.files(.), sep="/") %>%
sapply(source)
}
paste(path.git, "AnalyTools", sep="/") %>% source.all
paste(path.git, "Github_ScrapR",sep="/") %>% source.all
#' Before I forget, here's what we did
#' 1) Installed RTools 3.3.
#' 2) Edited the goddamned path because RTools wasn't capable of this itself
#' 3) Performed the following installs in R:
#'     * devtools::install_github("RcppCore/Rcpp")
#'     * devtools::install_github("rstats-db/DBI")
#'     * devtools::install_github("rstats-db/RPostgres")
#' 4) Created a yaml file that holds the database connections.
#' 5) Added some unknown stuff into my .RProfile
show.github.path('users/robertzk')
list.repos('users/robertzk')
list.repos <- function(path){
path <- if(grepl('.+/repos$',path)) {path} else{paste(path,'repos',sep="/")}
show.github.path(path) %>%
look.for('full_name')
}
list.repos('users/robertzk')
install.path <- function(path){
for(r in list.repos(path)){
tryCatch(
{install_github(r)}
,error=function(e){cat("ERROR :",conditionMessage(e), "\n")}
)
}
}
install.path('users/robertzk')
################################### HEADER ###################################
lib <- paste0(path.projects,"/Data_Sci/Github_Scraper")
setwd(lib)
source('show.github.path.R')
source('code.db.R')
################################ END HEADER ##################################
search.repo <- function(url, regex, file.type='\\..+',verbose=F){
#Build the code.db from the url
message(paste("Scanning",url,"/...  Please be patient!"))
files <- code.db(url,verbose=verbose)
message("Scan Complete!")
#Return each file where the code matches the regex pattern.
files %>%
filter(
grepl(paste0(file.type,'$'),name,ignore.case=T)
,grepl(regex,code,ignore.case=T)
) %>%
mutate(
loc = sapply(code, function(x) regexpr(regex, x, ignore.case=T)[1], USE.NAMES=F)
,code = paste0("..." ,substring(code, try(loc - 25,T), try(loc + 25,T)),"...")
) %>%
select(name,code)
}
search.repos <- function(urls, regex, file.type='\\..+',verbose=F){
lapply(urls, function(x) search.repo(x, regex, file.type,verbose=verbose)) %>%
do.call(rbind, .) %>%
return
}
#Some example searches of search.repo
# search.repo('repos/avantcredit/analytics-partners','select','.R')
# search.repo('repos/robertzk/3chessengine','rook')
# search.repo('repos/robertzk/3chessengine',"var [A-Za-z, ]+",file.type=".js")
#Example using search.repos
# repos <- c(
#    "repos/avantcredit/analytics-partners"
#   ,"repos/avantcredit/avant"
# )
# search.repos(repos, 'looker_query',verbose=T)
#Fun null-result example, make sure this does not error. It takes a while.
# repos = c('repos/avantcredit/avant','repos/avantcredit/avant-basic')
# search.repos(repos, 'looker.yml')
paste(path.git, "Github_ScrapR",sep="/") %>% source.all
paste(path.git, "Github_ScrapR",sep="/") %>% source.all
paste(path.git, "Github_ScrapR",sep="/")
paste(path.git, "Github_ScrapR",sep="/") -> path
path %>%
paste(., list.files(.), sep="/")
path %>%
paste(., list.files(.), sep="/") %>% filter(T)
path %>%
paste(., list.files(.), sep="/") %>% grep('.+/.R')
path %>%
paste(., list.files(.), sep="/") %>% grep('.+/.R',.)
path %>%
paste(., list.files(.), sep="/") %>% grep('.+.R',.)
path %>%
paste(., list.files(.), sep="/") %>% grep('.+\\.R',.)
?grep
path %>%
paste(., list.files(.), sep="/") %>% grep('.+\\.R',., value=T)
source.all <- function(path){
path %>%
paste(., list.files(.), sep="/") %>%
grep('.+\\.R',., value=T) %>%
sapply(source)
}
paste(path.git, "Github_ScrapR",sep="/") %>% source.all
library('curl')
library('jsonlite')
library('httpuv')
library('httr')
library('dplyr')
# Function returns the content of a github url
show.github.path <- function(url,two.fac=0){
thing <- GET(
paste("https://api.github.com/",url,sep="")
,authenticate(GITHUB_USER, GITHUB_TOKEN)
,add_headers("X-GitHub-OTP" = two.fac)
)
content(thing)
}
#Try various paths to make sure it's working.
# show.github.path("user")
# show.github.path("issues")
# show.github.path("user/issues")
# show.github.path("user/repos")
# show.github.path("orgs/avantcredit/issues")
show.github.path("user")
show.github.path("issues")
show.github.path("user/issues")
show.github.path("user/repos")
show.github.path("orgs/avantcredit/issues")
show.github.path("orgs/avantcredit/analytics-partners/issues")
show.github.path("user/issues")
show.github.path("user/repos")
show.github.path("user/repos")[[1]]
show.github.path("user/repos") %>% look.for('full_name')
show.github.path("user/repos")
path.git
lib <- paste0(path.git,"/Github_ScrapR")
setwd(lib)
lib
source('show.github.path.R')
source('get.git.R')
?source
NUM_INSTALLMENTS = 2
DAYS_DELINQUENT = 7
AFTER_DATE = as.Date('1900-01-01')
INCLUDE_CUSTOMER_ID = FALSE
library(avant)
install_github('peterhurford/batchman')
library(avant)
install_github('robertzk/cachemeifyoucan')
install_github('avantcredit/dbtest')
install_github('robertzk/cachemeifyoucan')
library(avant)
if (!DAYS_DELINQUENT %in% c(0, 7, 30, 60)) {
stop("DAYS_DELINQUENT must be 0, 7, 30, 60")
}
if (is.character(AFTER_DATE)) AFTER_DATE <- as.Date(AFTER_DATE)
# Get default indicator from looker
dictionary <- list(
"uk_dw"
, "default_data"
, c(
"default_data.loan_id"
, "default_data.customer_id"
, "default_data.loan_created_date"
, "default_data.installment_number"
, "default_data.installment_date"
, "default_data.early_paid_off"
, "default_data.default_initial"
, "default_data.default_7"
, "default_data.default_30"
, "default_data.default_60"
, "default_data.offset")
, "default_data.loan_id: >0"
, limit = 99999999
, locale = "DW"
)
loan_installments <- do.call(looker_query, dictionary)
head(loan_installments)
default_indicator <- switch(as.character(DAYS_DELINQUENT),
'0'  = 'defaulted0',
'7'  = 'defaulted7',
'30' = 'defaulted30',
'60' = 'defaulted60',
stop("Invalid DAYS_DELINQUENT"))
keep <- c(default_indicator,
"loan_id", "customer_id", "created_at", "installment_num",
"inst_due_date", "paid_off")
loan_installments <- loan_installments[,keep]
head(loan_installments)
keep <- c(default_indicator,
"loan_id", "customer_id", "created_at", "installment_num",
"inst_due_date", "paid_off")
keep
loan_installments <- loan_installments[,keep]
loan_installments[,keep]
colnames(loan_installments)
names(loan_installments) <- c("customer_id", "defaulted60", "defaulted30", "defaulted7", "defaulted0", "paid_off",
"inst_due_date", "installment_num", "created_at", "loan_id", "offset")
loan_installments <- loan_installments[as.Date(loan_installments$created_at) > AFTER_DATE, ]
default_indicator <- switch(as.character(DAYS_DELINQUENT),
'0'  = 'defaulted0',
'7'  = 'defaulted7',
'30' = 'defaulted30',
'60' = 'defaulted60',
stop("Invalid DAYS_DELINQUENT"))
keep <- c(default_indicator,
"loan_id", "customer_id", "created_at", "installment_num",
"inst_due_date", "paid_off")
loan_installments <- loan_installments[,keep]
names(loan_installments)[1] <- 'default'
loan_installments <- loan_installments[Sys.Date() - as.Date(loan_installments$inst_due_date) > DAYS_DELINQUENT, ]
# look only at first few installments per loan
loan_installments <- loan_installments[as.numeric(loan_installments$installment_num) <= NUM_INSTALLMENTS, ]
Ramd::packages('plyr')
loans <- plyr::ddply(loan_installments, .(loan_id), summarize,
customer_id = customer_id[1],
dep_var = ifelse(any(default == "Yes"), 1, 0),
created_at = created_at[1],
num_installments = length(loan_id),
prepaid = ifelse(any(paid_off == "Yes"), 1, 0))
loans$dep_var <- as.integer(loans$dep_var)
head(loans)
loans$prepaid <- as.integer(loans$prepaid)
retro_data <- s3mpi::s3read('data/default/en-GB/retro1.0.1')
looker_query('https://springcoin.looker.com/explore/avant/loans?fields=loans.id,loans.customer_id,loans.status&f%5Bloans.status%5D=charged_off,+current,+late,+paid_off&sorts=loans.id&limit=500&vis=%7B%22type%22:%22looker_column%22%7D&filter_config=%7B%22loans.status%22:%5B%7B%22type%22:%22advanced%22,%22values%22:%5B%7B%22constant%22:%22charged_off,+current,+late,+paid_off%22%7D,%7B%7D%5D,%22id%22:0%7D%5D%7D&show=data&title=UK+Mail+1&look_id=419&run=1')
library(roxygen2)
